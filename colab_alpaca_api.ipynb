{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN6A7oGsnpDiSt42jNBe3rj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MarcelloCarboni/alpaca-api/blob/main/colab_alpaca_api.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install the requirements"
      ],
      "metadata": {
        "id": "YjIvb6G6R_ZM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6pFlJfIjQIa_",
        "outputId": "cd63fa47-86a8-4a1a-fb55-3d6f0b7b283d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m469.0/469.0 KB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 KB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.9/132.9 KB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.2/212.2 KB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.8/199.8 KB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.2/114.2 KB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.6/264.6 KB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 KB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[33mWARNING: Skipping transformers as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33m  WARNING: Did not find branch or tag 'c3dc391', assuming revision or ref.\u001b[0m\u001b[33m\n",
            "\u001b[0m  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m99.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.8/212.8 KB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for peft (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.2/84.2 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.9/dist-packages (2.2.3)\n",
            "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.9/dist-packages (from flask) (8.1.3)\n",
            "Requirement already satisfied: importlib-metadata>=3.6.0 in /usr/local/lib/python3.9/dist-packages (from flask) (6.0.0)\n",
            "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.9/dist-packages (from flask) (2.2.3)\n",
            "Requirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.9/dist-packages (from flask) (3.1.2)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.9/dist-packages (from flask) (2.1.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata>=3.6.0->flask) (3.15.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from Jinja2>=3.0->flask) (2.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install -q datasets loralib sentencepiece\n",
        "!pip uninstall transformers\n",
        "!pip install -q git+https://github.com/zphang/transformers@c3dc391\n",
        "!pip -q install git+https://github.com/huggingface/peft.git\n",
        "!pip -q install bitsandbytes\n",
        "!pip install flask"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download the script"
      ],
      "metadata": {
        "id": "KITgsl3XSCc0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/MarcelloCarboni/alpaca-api/main/alpaca-api.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E_gM6nOMTENl",
        "outputId": "930442d2-de9c-4627-c55d-0339368a3709"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-03-22 14:54:27--  https://raw.githubusercontent.com/MarcelloCarboni/alpaca-api/main/alpaca-api.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1885 (1.8K) [text/plain]\n",
            "Saving to: ‘alpaca-api.py’\n",
            "\n",
            "alpaca-api.py       100%[===================>]   1.84K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-03-22 14:54:28 (34.9 MB/s) - ‘alpaca-api.py’ saved [1885/1885]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download Ngrok and add your ngrok authtoken"
      ],
      "metadata": {
        "id": "HJW3P1WSSRm6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://bin.equinox.io/c/bNyj1mQVY4c/ngrok-v3-stable-linux-amd64.tgz\n",
        "!tar -xzvf ngrok-v3-stable-linux-amd64.tgz\n",
        "\n",
        "!./ngrok config add-authtoken "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kcWBXZq7RXMU",
        "outputId": "0a00b0dd-8ff7-48fd-d2dc-695ad031be4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-03-22 13:34:40--  https://bin.equinox.io/c/bNyj1mQVY4c/ngrok-v3-stable-linux-amd64.tgz\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 52.202.168.65, 54.237.133.81, 54.161.241.46, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|52.202.168.65|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 8162036 (7.8M) [application/octet-stream]\n",
            "Saving to: ‘ngrok-v3-stable-linux-amd64.tgz’\n",
            "\n",
            "ngrok-v3-stable-lin 100%[===================>]   7.78M  3.19MB/s    in 2.4s    \n",
            "\n",
            "2023-03-22 13:34:43 (3.19 MB/s) - ‘ngrok-v3-stable-linux-amd64.tgz’ saved [8162036/8162036]\n",
            "\n",
            "ngrok\n",
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Start the tunnel"
      ],
      "metadata": {
        "id": "UpMdRxRqShAz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "get_ipython().system_raw('./ngrok http 5000 &')"
      ],
      "metadata": {
        "id": "Slvj-HBKR5T1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get the link to the API"
      ],
      "metadata": {
        "id": "MRvScRgQSldg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -s http://localhost:4040/api/tunnels | python3 -c \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xoBcMb2YR53b",
        "outputId": "8dd7a4c4-d77a-407a-b26c-bfdf187e432e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://0ef5-34-87-13-9.ap.ngrok.io\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Start the main application"
      ],
      "metadata": {
        "id": "1h1UHHfBrBPi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from IPython import get_ipython\n",
        "# get_ipython().system_raw('python3 alpaca-api.py &')\n",
        "!python3 alpaca-api.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fr_-QHzMQNS_",
        "outputId": "1907b460-1cd0-4d8e-f82d-37191097c6c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===================================BUG REPORT===================================\n",
            "Welcome to bitsandbytes. For bug reports, please submit your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
            "================================================================================\n",
            "/usr/local/lib/python3.9/dist-packages/bitsandbytes/cuda_setup/main.py:136: UserWarning: /usr/lib64-nvidia did not contain libcudart.so as expected! Searching further paths...\n",
            "  warn(msg)\n",
            "/usr/local/lib/python3.9/dist-packages/bitsandbytes/cuda_setup/main.py:136: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/sys/fs/cgroup/memory.events /var/colab/cgroup/jupyter-children/memory.events')}\n",
            "  warn(msg)\n",
            "/usr/local/lib/python3.9/dist-packages/bitsandbytes/cuda_setup/main.py:136: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('//colab.research.google.com/tun/m/cc48301118ce562b961b3c22d803539adc1e0c19/gpu-t4-s-2eb36v4hxnp6g --tunnel_background_save_delay=10s --tunnel_periodic_background_save_frequency=30m0s --enable_output_coalescing=true --output_coalescing_required=true'), PosixPath('--listen_host=172.28.0.12 --target_host=172.28.0.12 --tunnel_background_save_url=https')}\n",
            "  warn(msg)\n",
            "/usr/local/lib/python3.9/dist-packages/bitsandbytes/cuda_setup/main.py:136: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/env/python')}\n",
            "  warn(msg)\n",
            "/usr/local/lib/python3.9/dist-packages/bitsandbytes/cuda_setup/main.py:136: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('module'), PosixPath('//ipykernel.pylab.backend_inline')}\n",
            "  warn(msg)\n",
            "CUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching /usr/local/cuda/lib64...\n",
            "CUDA SETUP: CUDA runtime path found: /usr/local/cuda/lib64/libcudart.so\n",
            "CUDA SETUP: Highest compute capability among GPUs detected: 7.5\n",
            "CUDA SETUP: Detected CUDA version 118\n",
            "CUDA SETUP: Loading binary /usr/local/lib/python3.9/dist-packages/bitsandbytes/libbitsandbytes_cuda118.so...\n",
            "Overriding torch_dtype=None with `torch_dtype=torch.float16` due to requirements of `bitsandbytes` to enable model loading in mixed int8. Either pass torch_dtype=torch.float16 or don't pass this argument at all to remove this warning.\n",
            "Loading checkpoint shards: 100% 33/33 [01:04<00:00,  1.97s/it]\n",
            " * Serving Flask app 'alpaca-api'\n",
            " * Debug mode: off\n",
            "\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            "Generating...\n",
            "2023-03-22 14:56:10.772153: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-03-22 14:56:13.964460: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-22 14:56:13.964843: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-22 14:56:13.964869: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            " Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "Tell me a joke about joe mama.\n",
            "Joe Mama was sitting in his office when he got a call from his boss, who told him to go out and get some coffee for everyone at work. Joe said \"Sure thing!\" but then realized he didn't have any money on him so he went home first to grab it. When he returned with the cash, however, he found himself locked outside of his house! He knocked on the door until someone finally answered, only to find it was his mother-in-law. She asked what he wanted, and he replied: \"I need your help.\"\n",
            "127.0.0.1 - - [22/Mar/2023 14:56:46] \"POST /ask HTTP/1.1\" 200 -\n",
            "127.0.0.1 - - [22/Mar/2023 14:57:21] \"\u001b[31m\u001b[1mGET /ask HTTP/1.1\u001b[0m\" 405 -\n",
            "Generating...\n",
            " Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "Where is Marrubiu?\n",
            "### Instruction:\n",
            "Where is Marrubiu?\n",
            "### Response:\n",
            "Marrubiu is located in Australia, on the east coast of Queensland state. It has a population of around 100 people and lies about 25 km northwest from Townsville city centre.\n",
            "127.0.0.1 - - [22/Mar/2023 14:58:48] \"POST /ask HTTP/1.1\" 200 -\n",
            "Generating...\n",
            " Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "In the C language, what is a pointer?\n",
            "A pointer in the C programming language is a variable which holds the address of another data type such as integer or string.\n",
            "127.0.0.1 - - [22/Mar/2023 15:00:05] \"POST /ask HTTP/1.1\" 200 -\n",
            "Generating...\n",
            " Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "Where is the city of Cagliari located?\n",
            "### Response:\n",
            "Cagliari, Italy's capital on Sardinia island, lies in southern Europe and has a Mediterranean climate with mild winters and warm summers.\n",
            "127.0.0.1 - - [22/Mar/2023 15:00:54] \"POST /ask HTTP/1.1\" 200 -\n",
            "Generating...\n",
            " Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "Who are you? (Instruction)\n",
            "Response: I am John Smith, 25 years old and currently living in New York City.\n",
            "127.0.0.1 - - [22/Mar/2023 15:13:05] \"POST /ask HTTP/1.1\" 200 -\n",
            "Generating...\n",
            " Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "Who is Hatsune Miku?\n",
            "Hatsune Miku (初音ミク) is a humanoid persona voiced by a singing synthesizer application developed by Crypton Future Media in 2007. She has since become one of Japan's most popular virtual idols, with millions of fans worldwide and over $1 billion worth of merchandise sold to date.\n",
            "127.0.0.1 - - [22/Mar/2023 15:19:22] \"POST /ask HTTP/1.1\" 200 -\n"
          ]
        }
      ]
    }
  ]
}